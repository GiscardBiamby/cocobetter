{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ce870a-4978-4600-846d-09a32d513e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21385f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aeadb83-0c01-41a3-8731-5ce080c4ad10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbiamby/mambaforge/envs/cocobetter/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import typing\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as pil_img\n",
    "import seaborn as sns\n",
    "import simdjson as json\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b3e61-b7f8-4549-b951-cda5d4583c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db4b9ce-a510-464a-91d1-f08dbd5c1717",
   "metadata": {},
   "source": [
    "## Load and Inspect the Newly Saved RefCOCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d90829-2db8-4fc2-a1ab-771bd6d4e785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REFSEG_DIR = Path(\"/shared/gbiamby/data/refer_seg/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990b244c-e08e-45a5-b288-225d2698e64c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "============================================================================================================================================================================================================================\n",
      "Dataset: fprefcocog_v002(berkeley)\n",
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcocog_v002/refs(berkeley).p'\n",
      "Loaded 49822 refs\n",
      "loading annotations into memory...\n",
      "Done (t=17.77s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "VALID_SPLITS = {\n",
    "    \"R-refcoco\": [\"unc\"],\n",
    "    \"R-refcoco+\": [\"unc\"],\n",
    "    \"R-refcocog\": [\"umd\"],\n",
    "    \"refclef\": [\"berkeley\", \"unc\"],\n",
    "    \"refcoco\": [\"google\"],\n",
    "    \"refcoco+\": [\"unc\"],\n",
    "    \"refcocog\": [\"google\", \"umd\"],\n",
    "    # \"fprefcoco_v002\": [\"berkeley\"],\n",
    "    # \"fprefcoco+_v002\": [\"berkeley\"],\n",
    "    # \"fprefcocog_v002\": [\"berkeley\"],\n",
    "    \"fprefcoco_v002\": [\"berkeley_exclude_unified\"],\n",
    "    \"fprefcoco+_v002\": [\"berkeley_exclude_unified\"],\n",
    "    \"fprefcocog_v002\": [\"berkeley_exclude_unified\"],\n",
    "}\n",
    "\n",
    "\n",
    "def build_refcoco(refseg_path: Path, dataset_name: str, split_by: str = None) -> COCO:\n",
    "    assert dataset_name in VALID_SPLITS, dataset_name\n",
    "    if split_by is None:\n",
    "        split_by = VALID_SPLITS[dataset_name][0]\n",
    "    else:\n",
    "        assert split_by in VALID_SPLITS[dataset_name]\n",
    "    coco = COCO(\n",
    "        refseg_path / dataset_name / \"instances.json\",\n",
    "        is_ref_dataset=True,\n",
    "        dataset_name=dataset_name,\n",
    "        split_by=split_by,\n",
    "    )\n",
    "    return coco\n",
    "\n",
    "\n",
    "df_aggs = []\n",
    "for ds_name in [\"fprefcocog_v002\"]:\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"=\" * 220)\n",
    "    print(f\"Dataset: {ds_name}(berkeley)\")\n",
    "    coco = COCO(\n",
    "        REFSEG_DIR,\n",
    "        is_ref_dataset=True,\n",
    "        dataset_name=ds_name,\n",
    "        split_by=\"berkeley\",\n",
    "    )\n",
    "    ## if you are using cocobetter you can output some stats by un-commenting these lines:\n",
    "    # df_refcoco, df_refcoco_agg = coco.get_ref_stats()\n",
    "    # df_aggs.append(df_refcoco_agg)\n",
    "\n",
    "\n",
    "if len(df_aggs) > 0:\n",
    "    df_aggs = pd.concat(df_aggs)\n",
    "    display(df_aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9dd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c5d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys:  dict_keys(['images', 'annotations'])\n",
      "1300 2573\n"
     ]
    }
   ],
   "source": [
    "# Load the seem version to inspect it\n",
    "seem_json_path = Path(\"/home/gbiamby/proj/SEEM/.xdecoder_data/coco/annotations/refcocog_umd_val.json\")\n",
    "seem_json = json.load(open(seem_json_path, \"r\"))\n",
    "print(\"keys: \", seem_json.keys())\n",
    "print(len(seem_json[\"images\"]), len(seem_json[\"annotations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3f40e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "<class 'dict'> <class 'dict'>\n",
      "dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id'])\n",
      "dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id', 'split', 'sentences', 'file_name', 'ann_id', 'sent_ids', 'ref_id'])\n",
      "{'tokens': ['a', 'bush', 'of', 'plant', 'behind', 'middle', 'woman'], 'raw': 'a bush of plant behind middle woman', 'sent_id': 61, 'sent': 'a bush of plant behind middle woman'}\n"
     ]
    }
   ],
   "source": [
    "print(type(seem_json[\"images\"]), type(seem_json[\"annotations\"]))\n",
    "print(type(seem_json[\"images\"][0]), type(seem_json[\"annotations\"][0]))\n",
    "print(seem_json[\"images\"][0].keys())\n",
    "print(seem_json[\"annotations\"][0].keys())\n",
    "print(seem_json[\"annotations\"][0][\"sentences\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27bde429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "============================================================================================================================================================================================================================\n",
      "Dataset: fprefcoco_v002(berkeley)\n",
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcoco_v002/refs(berkeley_exclude_unified).p'\n",
      "Loaded 50000 refs\n",
      "loading annotations into memory...\n",
      "Done (t=9.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Converting:  fprefcoco_v002\n",
      "ref:  {'sent_ids': [13689, 13690, 13691], 'file_name': 'COCO_train2014_000000526754_0.jpg', 'ann_id': 592886, 'ref_id': 4808, 'image_id': 526754, 'split': 'val', 'sentences': [{'tokens': ['zebra', 'creature', 'front', 'and', 'center'], 'raw': 'zebra creature front and center', 'sent_id': 13689, 'sent': 'zebra creature front and center', 'spcy_WORD': ['zebra', 'creature', 'front', 'and', 'center'], 'spcy_DEP': ['compound', 'ROOT', 'advmod', 'cc', 'conj'], 'spcy_POS': ['NOUN', 'NOUN', 'ADJ', 'CCONJ', 'NOUN'], 'spcy_LEM': ['zebra', 'creature', 'front', 'and', 'center'], 'spcy_TAG': ['NN', 'NN', 'JJ', 'CC', 'NN'], 'spcy_IS_STOP': [False, False, True, True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['zebra creature'], 'is_false_premise': False, 'exist': True}, {'tokens': ['zebra'], 'raw': 'zebra', 'sent_id': 13690, 'sent': 'zebra', 'spcy_WORD': ['zebra'], 'spcy_DEP': ['ROOT'], 'spcy_POS': ['PROPN'], 'spcy_LEM': ['zebra'], 'spcy_TAG': ['NNP'], 'spcy_IS_STOP': [False], 'spcy_ENTS': ['zebra'], 'spcy_NOUN_CHUNKS': ['zebra'], 'is_false_premise': False, 'exist': True}, {'tokens': ['whole', 'zebra'], 'raw': 'whole zebra', 'sent_id': 13691, 'sent': 'whole zebra', 'spcy_WORD': ['whole', 'zebra'], 'spcy_DEP': ['amod', 'ROOT'], 'spcy_POS': ['ADJ', 'NOUN'], 'spcy_LEM': ['whole', 'zebra'], 'spcy_TAG': ['JJ', 'NN'], 'spcy_IS_STOP': [True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['whole zebra'], 'is_false_premise': False, 'exist': True}, {'tokens': ['unicorn', 'creature', 'front', 'and', 'center'], 'raw': 'unicorn creature front and center', 'sent_id': -1, 'sent': 'unicorn creature front and center', 'spcy_WORD': ['unicorn', 'creature', 'front', 'and', 'center'], 'spcy_DEP': ['compound', 'ROOT', 'advmod', 'cc', 'conj'], 'spcy_POS': ['NOUN', 'NOUN', 'ADJ', 'CCONJ', 'NOUN'], 'spcy_LEM': ['unicorn', 'creature', 'front', 'and', 'center'], 'spcy_TAG': ['NN', 'NN', 'JJ', 'CC', 'NN'], 'spcy_IS_STOP': [False, False, True, True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['unicorn creature'], 'main_subject': ['creature'], 'ref_id': 4808, 'ann_id': 592886, 'gt_sent_id': 13689, 'gt_sent': 'zebra creature front and center', 'is_false_premise': True, 'change_type': 'other_subject', 'exist': False}, {'tokens': ['unicorn'], 'raw': 'unicorn', 'sent_id': -1, 'sent': 'unicorn', 'spcy_WORD': ['unicorn'], 'spcy_DEP': ['ROOT'], 'spcy_POS': ['NOUN'], 'spcy_LEM': ['unicorn'], 'spcy_TAG': ['NN'], 'spcy_IS_STOP': [False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['unicorn'], 'main_subject': ['unicorn'], 'ref_id': 4808, 'ann_id': 592886, 'gt_sent_id': 13690, 'gt_sent': 'zebra', 'is_false_premise': True, 'change_type': 'main_subject', 'exist': False}, {'tokens': ['whole', 'unicorn'], 'raw': 'whole unicorn', 'sent_id': -1, 'sent': 'whole unicorn', 'spcy_WORD': ['whole', 'unicorn'], 'spcy_DEP': ['amod', 'ROOT'], 'spcy_POS': ['ADJ', 'NOUN'], 'spcy_LEM': ['whole', 'unicorn'], 'spcy_TAG': ['JJ', 'NN'], 'spcy_IS_STOP': [True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['whole unicorn'], 'main_subject': ['unicorn'], 'ref_id': 4808, 'ann_id': 592886, 'gt_sent_id': 13691, 'gt_sent': 'whole zebra', 'is_false_premise': True, 'change_type': 'main_subject', 'exist': False}], 'category_id': 24}\n",
      "image:  dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id'])\n",
      "ann:  dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "50000\n",
      "{'train_exclude', 'testA', 'val', 'train', 'testB'}\n",
      "split:  train_exclude\n",
      "Num imgs:  1891\n",
      "Num refs:  4470\n",
      "Num ann_ids:  4470\n",
      "Num ref_ids:  4470\n",
      "New annotations:  4470\n",
      "split:  testA\n",
      "Num imgs:  750\n",
      "Num refs:  1975\n",
      "Num ann_ids:  1975\n",
      "Num ref_ids:  1975\n",
      "New annotations:  1975\n",
      "split:  val\n",
      "{'license': 3, 'file_name': 'COCO_train2014_000000526754.jpg', 'coco_url': 'http://mscoco.org/images/526754', 'height': 640, 'width': 537, 'date_captured': '2013-11-18 17:29:55', 'flickr_url': 'http://farm9.staticflickr.com/8039/7929059134_3b5b18f8ec_z.jpg', 'id': 526754}\n",
      "<class 'list'>\n",
      "{'tokens': ['zebra', 'creature', 'front', 'and', 'center'], 'raw': 'zebra creature front and center', 'sent_id': 13689, 'sent': 'zebra creature front and center'}\n",
      "Num imgs:  1500\n",
      "Num refs:  3811\n",
      "Num ann_ids:  3811\n",
      "Num ref_ids:  3811\n",
      "New annotations:  3811\n",
      "split:  train\n",
      "Num imgs:  15103\n",
      "Num refs:  37934\n",
      "Num ann_ids:  37934\n",
      "Num ref_ids:  37934\n",
      "New annotations:  37934\n",
      "split:  testB\n",
      "Num imgs:  750\n",
      "Num refs:  1810\n",
      "Num ann_ids:  1810\n",
      "Num ref_ids:  1810\n",
      "New annotations:  1810\n",
      "\n",
      "\n",
      "\n",
      "============================================================================================================================================================================================================================\n",
      "Dataset: fprefcoco+_v002(berkeley)\n",
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcoco+_v002/refs(berkeley_exclude_unified).p'\n",
      "Loaded 49856 refs\n",
      "loading annotations into memory...\n",
      "Done (t=5.91s)\n",
      "creating index...\n",
      "index created!\n",
      "Converting:  fprefcoco+_v002\n",
      "ref:  {'sent_ids': [0, 1, 2], 'file_name': 'COCO_train2014_000000581857_16.jpg', 'ann_id': 1719310, 'ref_id': 0, 'image_id': 581857, 'split': 'train', 'sentences': [{'tokens': ['navy', 'blue', 'shirt'], 'raw': 'navy blue shirt', 'sent_id': 0, 'sent': 'navy blue shirt', 'spcy_WORD': ['navy', 'blue', 'shirt'], 'spcy_DEP': ['amod', 'amod', 'ROOT'], 'spcy_POS': ['ADJ', 'ADJ', 'NOUN'], 'spcy_LEM': ['navy', 'blue', 'shirt'], 'spcy_TAG': ['JJ', 'JJ', 'NN'], 'spcy_IS_STOP': [False, False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['navy blue shirt'], 'is_false_premise': False, 'exist': True}, {'tokens': ['woman', 'back', 'in', 'blue'], 'raw': 'woman back in blue', 'sent_id': 1, 'sent': 'woman back in blue', 'spcy_WORD': ['woman', 'back', 'in', 'blue'], 'spcy_DEP': ['ROOT', 'advmod', 'prep', 'pobj'], 'spcy_POS': ['NOUN', 'ADV', 'ADP', 'NOUN'], 'spcy_LEM': ['woman', 'back', 'in', 'blue'], 'spcy_TAG': ['NN', 'RB', 'IN', 'NN'], 'spcy_IS_STOP': [False, True, True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['woman', 'blue'], 'is_false_premise': False, 'exist': True}, {'tokens': ['blue', 'shirt'], 'raw': 'blue shirt', 'sent_id': 2, 'sent': 'blue shirt', 'spcy_WORD': ['blue', 'shirt'], 'spcy_DEP': ['amod', 'ROOT'], 'spcy_POS': ['ADJ', 'NOUN'], 'spcy_LEM': ['blue', 'shirt'], 'spcy_TAG': ['JJ', 'NN'], 'spcy_IS_STOP': [False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['blue shirt'], 'is_false_premise': False, 'exist': True}, {'tokens': ['yellow', 'shirt'], 'raw': 'yellow shirt', 'sent_id': -1, 'sent': 'yellow shirt', 'spcy_WORD': ['yellow', 'shirt'], 'spcy_DEP': ['amod', 'ROOT'], 'spcy_POS': ['ADJ', 'NOUN'], 'spcy_LEM': ['yellow', 'shirt'], 'spcy_TAG': ['JJ', 'NN'], 'spcy_IS_STOP': [False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['yellow shirt'], 'main_subject': ['shirt'], 'ref_id': 0, 'ann_id': 1719310, 'gt_sent_id': 0, 'gt_sent': 'navy blue shirt', 'is_false_premise': True, 'change_type': 'other_subject', 'exist': False}, {'tokens': ['woman', 'back', 'in', 'red'], 'raw': 'woman back in red', 'sent_id': -1, 'sent': 'woman back in red', 'spcy_WORD': ['woman', 'back', 'in', 'red'], 'spcy_DEP': ['ROOT', 'advmod', 'prep', 'pobj'], 'spcy_POS': ['NOUN', 'ADV', 'ADP', 'NOUN'], 'spcy_LEM': ['woman', 'back', 'in', 'red'], 'spcy_TAG': ['NN', 'RB', 'IN', 'NN'], 'spcy_IS_STOP': [False, True, True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['woman', 'red'], 'main_subject': ['woman'], 'ref_id': 0, 'ann_id': 1719310, 'gt_sent_id': 1, 'gt_sent': 'woman back in blue', 'is_false_premise': True, 'change_type': 'other_subject', 'exist': False}, {'tokens': ['purple', 'shirt'], 'raw': 'purple shirt', 'sent_id': -1, 'sent': 'purple shirt', 'spcy_WORD': ['purple', 'shirt'], 'spcy_DEP': ['amod', 'ROOT'], 'spcy_POS': ['ADJ', 'NOUN'], 'spcy_LEM': ['purple', 'shirt'], 'spcy_TAG': ['JJ', 'NN'], 'spcy_IS_STOP': [False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['purple shirt'], 'main_subject': ['shirt'], 'ref_id': 0, 'ann_id': 1719310, 'gt_sent_id': 2, 'gt_sent': 'blue shirt', 'is_false_premise': True, 'change_type': 'other_subject', 'exist': False}], 'category_id': 1}\n",
      "image:  dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id'])\n",
      "ann:  dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "49856\n",
      "{'train_exclude', 'testA', 'val', 'train', 'testB'}\n",
      "split:  train_exclude\n",
      "Num imgs:  1891\n",
      "Num refs:  4461\n",
      "Num ann_ids:  4461\n",
      "Num ref_ids:  4461\n",
      "New annotations:  4461\n",
      "split:  testA\n",
      "Num imgs:  750\n",
      "Num refs:  1975\n",
      "Num ann_ids:  1975\n",
      "Num ref_ids:  1975\n",
      "New annotations:  1975\n",
      "split:  val\n",
      "Num imgs:  1500\n",
      "Num refs:  3805\n",
      "Num ann_ids:  3805\n",
      "Num ref_ids:  3805\n",
      "New annotations:  3805\n",
      "split:  train\n",
      "{'license': 4, 'file_name': 'COCO_train2014_000000581857.jpg', 'coco_url': 'http://mscoco.org/images/581857', 'height': 640, 'width': 427, 'date_captured': '2013-11-19 19:21:09', 'flickr_url': 'http://farm6.staticflickr.com/5125/5309665572_6b7872c76a_z.jpg', 'id': 581857}\n",
      "<class 'list'>\n",
      "{'tokens': ['navy', 'blue', 'shirt'], 'raw': 'navy blue shirt', 'sent_id': 0, 'sent': 'navy blue shirt'}\n",
      "Num imgs:  15101\n",
      "Num refs:  37817\n",
      "Num ann_ids:  37817\n",
      "Num ref_ids:  37817\n",
      "New annotations:  37817\n",
      "split:  testB\n",
      "Num imgs:  750\n",
      "Num refs:  1798\n",
      "Num ann_ids:  1798\n",
      "Num ref_ids:  1798\n",
      "New annotations:  1798\n",
      "\n",
      "\n",
      "\n",
      "============================================================================================================================================================================================================================\n",
      "Dataset: fprefcocog_v002(berkeley)\n",
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcocog_v002/refs(berkeley_exclude_unified).p'\n",
      "Loaded 49822 refs\n",
      "loading annotations into memory...\n",
      "Done (t=1.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Converting:  fprefcocog_v002\n",
      "ref:  {'image_id': 546154, 'split': 'train', 'sentences': [{'tokens': ['the', 'tie', 'of', 'the', 'standing', 'man'], 'raw': 'The tie of the standing man', 'sent_id': 2, 'sent': 'the tie of the standing man', 'spcy_DEP': ['det', 'ROOT', 'prep', 'det', 'amod', 'pobj'], 'spcy_POS': ['DET', 'NOUN', 'ADP', 'DET', 'VERB', 'NOUN'], 'spcy_LEM': ['the', 'tie', 'of', 'the', 'stand', 'man'], 'spcy_TAG': ['DT', 'NN', 'IN', 'DT', 'VBG', 'NN'], 'spcy_IS_STOP': [True, False, True, True, False, False], 'spcy_ENTS': ['the tie of the standing man'], 'spcy_WORD': ['the', 'tie', 'of', 'the', 'standing', 'man'], 'spcy_NOUN_CHUNKS': ['the tie', 'the standing man'], 'is_false_premise': False, 'exist': True}, {'tokens': ['a', 'purple', 'tie', 'with', 'repetitive', 'circular', 'patterns'], 'raw': 'A purple tie with repetitive circular patterns.', 'sent_id': 3, 'sent': 'a purple tie with repetitive circular patterns', 'spcy_DEP': ['det', 'amod', 'ROOT', 'prep', 'amod', 'amod', 'pobj'], 'spcy_POS': ['DET', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN'], 'spcy_LEM': ['a', 'purple', 'tie', 'with', 'repetitive', 'circular', 'pattern'], 'spcy_TAG': ['DT', 'JJ', 'NN', 'IN', 'JJ', 'JJ', 'NNS'], 'spcy_IS_STOP': [True, False, False, True, False, False, False], 'spcy_ENTS': [], 'spcy_WORD': ['a', 'purple', 'tie', 'with', 'repetitive', 'circular', 'patterns'], 'spcy_NOUN_CHUNKS': ['a purple tie', 'repetitive circular patterns'], 'is_false_premise': False, 'exist': True}, {'tokens': ['the', 'tie', 'of', 'the', 'dancing', 'unicorn'], 'raw': 'the tie of the dancing unicorn', 'sent_id': -1, 'sent': 'the tie of the dancing unicorn', 'spcy_WORD': ['the', 'tie', 'of', 'the', 'dancing', 'unicorn'], 'spcy_DEP': ['det', 'ROOT', 'prep', 'det', 'amod', 'pobj'], 'spcy_POS': ['DET', 'NOUN', 'ADP', 'DET', 'VERB', 'NOUN'], 'spcy_LEM': ['the', 'tie', 'of', 'the', 'dance', 'unicorn'], 'spcy_TAG': ['DT', 'NN', 'IN', 'DT', 'VBG', 'NN'], 'spcy_IS_STOP': [True, False, True, True, False, False], 'spcy_ENTS': ['the tie of the dancing unicorn'], 'spcy_NOUN_CHUNKS': ['the tie', 'the dancing unicorn'], 'main_subject': ['tie'], 'ref_id': 0, 'ann_id': 298801, 'gt_sent_id': 2, 'gt_sent': 'the tie of the standing man', 'is_false_premise': True, 'change_type': 'NOT_MAIN_SUBJ', 'exist': False}, {'tokens': ['a', 'purple', 'tie', 'with', 'magical', 'circular', 'patterns'], 'raw': 'a purple tie with magical circular patterns', 'sent_id': -1, 'sent': 'a purple tie with magical circular patterns', 'spcy_WORD': ['a', 'purple', 'tie', 'with', 'magical', 'circular', 'patterns'], 'spcy_DEP': ['det', 'amod', 'ROOT', 'prep', 'amod', 'amod', 'pobj'], 'spcy_POS': ['DET', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN'], 'spcy_LEM': ['a', 'purple', 'tie', 'with', 'magical', 'circular', 'pattern'], 'spcy_TAG': ['DT', 'JJ', 'NN', 'IN', 'JJ', 'JJ', 'NNS'], 'spcy_IS_STOP': [True, False, False, True, False, False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['a purple tie', 'magical circular patterns'], 'main_subject': ['tie'], 'ref_id': 0, 'ann_id': 298801, 'gt_sent_id': 3, 'gt_sent': 'a purple tie with repetitive circular patterns', 'is_false_premise': True, 'change_type': 'NOT_MAIN_SUBJ', 'exist': False}], 'file_name': 'COCO_train2014_000000546154_298801.jpg', 'category_id': 32, 'ann_id': 298801, 'sent_ids': [2, 3], 'ref_id': 0}\n",
      "image:  dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id'])\n",
      "ann:  dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "49822\n",
      "{'test', 'train', 'train_exclude', 'val'}\n",
      "split:  test\n",
      "Num imgs:  2600\n",
      "Num refs:  5023\n",
      "Num ann_ids:  5023\n",
      "Num ref_ids:  5023\n",
      "New annotations:  5023\n",
      "split:  train\n",
      "{'license': 3, 'file_name': 'COCO_train2014_000000546154.jpg', 'coco_url': 'http://mscoco.org/images/546154', 'height': 480, 'width': 640, 'date_captured': '2013-11-18 05:42:48', 'flickr_url': 'http://farm4.staticflickr.com/3410/3208122782_1b783a9f04_z.jpg', 'id': 546154}\n",
      "<class 'list'>\n",
      "{'tokens': ['the', 'tie', 'of', 'the', 'standing', 'man'], 'raw': 'The tie of the standing man', 'sent_id': 2, 'sent': 'the tie of the standing man'}\n",
      "Num imgs:  20039\n",
      "Num refs:  37950\n",
      "Num ann_ids:  37949\n",
      "Num ref_ids:  37950\n",
      "New annotations:  37950\n",
      "split:  train_exclude\n",
      "Num imgs:  1860\n",
      "Num refs:  4276\n",
      "Num ann_ids:  4275\n",
      "Num ref_ids:  4276\n",
      "New annotations:  4276\n",
      "split:  val\n",
      "Num imgs:  1300\n",
      "Num refs:  2573\n",
      "Num ann_ids:  2573\n",
      "Num ref_ids:  2573\n",
      "New annotations:  2573\n"
     ]
    }
   ],
   "source": [
    "def create_fp_ann(coco: COCO, ref: Ref):\n",
    "    max_ann_id = max(coco.anns.keys())\n",
    "    new_ann_id = max_ann_id + 1\n",
    "    return {\n",
    "        \"segmentation\": [[]],\n",
    "        \"area\": 0.0,\n",
    "        \"iscrowd\": 0,\n",
    "        \"image_id\": ref[\"image_id\"],\n",
    "        \"bbox\": [0.0, 0.0, 0.0, 0.0],\n",
    "        \"category_id\": \"\",\n",
    "        \"id\": \"\",\n",
    "    }\n",
    "\n",
    "\n",
    "def convert_fpref(coco: COCO, output_dir: Path):\n",
    "    print(\"Converting: \", coco.dataset_name)\n",
    "    print(\"ref: \", coco.refs_data[0])\n",
    "    print(\"image: \", list(coco.imgs.values())[0].keys())\n",
    "    print(\"ann: \", list(coco.anns.values())[0].keys())\n",
    "    print(len(coco.refs_data))\n",
    "    splits = {r[\"split\"] for r in coco.refs_data}\n",
    "    print(splits)\n",
    "    for split in splits:\n",
    "        print(\"split: \", split)\n",
    "        output_path = output_dir / f\"{coco.dataset_name}_{split}.json\"\n",
    "        output_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        data = {\"images\": [], \"annotations\": []}\n",
    "        images, refs, annotations = {}, [], []\n",
    "        ann_ids, ref_ids = {}, {}\n",
    "\n",
    "        for i, ref in enumerate(coco.refs_data):\n",
    "            if ref[\"split\"] == split:\n",
    "                refs.append(ref)\n",
    "                images[ref[\"image_id\"]] = coco.imgs[ref[\"image_id\"]]\n",
    "                ann_ids[ref[\"ann_id\"]] = ref[\"ann_id\"]\n",
    "                ref_ids[ref[\"ref_id\"]] = ref[\"ref_id\"]\n",
    "                new_ann: dict = deepcopy(coco.anns[ref[\"ann_id\"]])\n",
    "                sents = [\n",
    "                    {\n",
    "                        \"tokens\": s[\"tokens\"],\n",
    "                        \"raw\": s[\"raw\"],\n",
    "                        \"sent_id\": s[\"sent_id\"],\n",
    "                        \"sent\": s[\"sent\"],\n",
    "                    }\n",
    "                    for s in ref[\"sentences\"]\n",
    "                ]\n",
    "                new_ann.update(\n",
    "                    {\n",
    "                        \"split\": ref[\"split\"],\n",
    "                        \"sentences\": sents,\n",
    "                        \"file_name\": ref[\"file_name\"],\n",
    "                        \"ann_id\": ref[\"ann_id\"],\n",
    "                        \"sent_ids\": ref[\"sent_ids\"],\n",
    "                        \"ref_id\": ref[\"ref_id\"],\n",
    "                    }\n",
    "                )\n",
    "                annotations.append(new_ann)\n",
    "                if i == 0:\n",
    "                    print(images[ref[\"image_id\"]])\n",
    "                    sents = new_ann[\"sentences\"]\n",
    "                    print(type(new_ann[\"sentences\"]))\n",
    "                    print(sents[0])\n",
    "\n",
    "        print(\"Num imgs: \", len(images))\n",
    "        print(\"Num refs: \", len(refs))\n",
    "        print(\"Num ann_ids: \", len(ann_ids))\n",
    "        print(\"Num ref_ids: \", len(ref_ids))\n",
    "        print(\"New annotations: \", len(annotations))\n",
    "        data = {\"images\": list(images.values()), \"annotations\": annotations}\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "\n",
    "for ds_name in [\"fprefcoco_v002\", \"fprefcoco+_v002\", \"fprefcocog_v002\"]:\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"=\" * 220)\n",
    "    print(f\"Dataset: {ds_name}(berkeley)\")\n",
    "    coco = COCO(\n",
    "        REFSEG_DIR,\n",
    "        is_ref_dataset=True,\n",
    "        dataset_name=ds_name,\n",
    "        split_by=\"berkeley_exclude_unified\",\n",
    "    )\n",
    "    convert_fpref(\n",
    "        coco, Path(\"/home/gbiamby/proj/SEEM/.xdecoder_data/coco/fp_ref_annotations/\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bdc7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_splits:  fprefcocog_v002\n",
      "split:  test\n",
      "split: test {'train'}\n",
      "split:  train\n",
      "split: train {'train'}\n",
      "split:  val\n",
      "split: val {'train'}\n"
     ]
    }
   ],
   "source": [
    "def test_splits(coco: COCO):\n",
    "    print(\"test_splits: \", coco.dataset_name)\n",
    "    splits = {r[\"split\"] for r in coco.refs_data}\n",
    "    for split in splits:\n",
    "        print(\"split: \", split)\n",
    "        images, refs, annotations = {}, [], []\n",
    "        ann_ids, ref_ids = {}, {}\n",
    "        img_splits = set()\n",
    "        for i, ref in enumerate(coco.refs_data):\n",
    "            if ref[\"split\"] == split:\n",
    "                img = coco.imgs[ref[\"image_id\"]]\n",
    "                img_split = (\n",
    "                    \"trainval\"\n",
    "                    if \"trainval\" in img[\"file_name\"]\n",
    "                    else \"train\"\n",
    "                    if \"train\" in img[\"file_name\"]\n",
    "                    else \"test\"\n",
    "                    if \"test\" in img[\"file_name\"]\n",
    "                    else \"val\"\n",
    "                    if \"val\" in img[\"file_name\"]\n",
    "                    else \"UNKNOWN\"\n",
    "                )\n",
    "                img_splits.add(img_split)\n",
    "        print(\"split:\", split, img_splits)\n",
    "\n",
    "\n",
    "test_splits(coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10156db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaca6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ad0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f82da92c-a96b-454d-ba77-e9f5b3d9ec83",
   "metadata": {},
   "source": [
    "The format is nearly identical to refcoco/refcocog. The difference is there are some additional properties in the sentences objects.\n",
    "\n",
    "`coco->images->refs->sentences`\n",
    "\n",
    "#### True sentences vs false premise:\n",
    "\n",
    "These two methods are equivalent ways of detecting if a sentence is a false premise one:\n",
    "\n",
    "`s[\"exist\"] == False` and `s[\"is_false_premise\"]`\n",
    "\n",
    "Usually these sentences also have `sent_id = -1`, but that is not guaranteed so don't rely on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "341661b1-1c61-4543-a13a-974e7e54c558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref has keys:  dict_keys(['image_id', 'split', 'sentences', 'file_name', 'category_id', 'ann_id', 'sent_ids', 'ref_id'])\n",
      "ref has 4 sentences\n",
      "sent_id:21606, is_FP:False, sent: 'a large polar bear looking at a smaller polar bear'\n",
      "sent_id:21607, is_FP:False, sent: 'white polar bear looking at another bear'\n",
      "sent_id:-1, is_FP:True, sent: 'a large penguin looking at a smaller penguin'\n",
      "\tchange_type:  \n",
      "\tparent_sent_id: 21606, parent_sent: 'a large polar bear looking at a smaller polar bear'\n",
      "sent_id:-1, is_FP:True, sent: 'white penguin looking at another penguin'\n",
      "\tchange_type:  \n",
      "\tparent_sent_id: 21607, parent_sent: 'white polar bear looking at another bear'\n"
     ]
    }
   ],
   "source": [
    "def display_ref(ref):\n",
    "    print(\"ref has keys: \", ref.keys())\n",
    "    print(f\"ref has {len(ref['sentences'])} sentences\")\n",
    "    for s in ref[\"sentences\"]:\n",
    "        # print(s.keys())\n",
    "        print(\n",
    "            f\"sent_id:{s['sent_id']}, is_FP:{s['is_false_premise']}, sent: '{s['sent']}'\"\n",
    "        )\n",
    "        if s[\"is_false_premise\"]:\n",
    "            print(\"\\tchange_type: \", s[\"change_type\"])\n",
    "            print(f\"\\tparent_sent_id: {s['gt_sent_id']}, parent_sent: '{s['gt_sent']}'\")\n",
    "\n",
    "\n",
    "def show_refexp_example(refcoco: COCO):\n",
    "    ref = refcoco.refs[1000]\n",
    "    display_ref(ref)\n",
    "\n",
    "\n",
    "show_refexp_example(coco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73450d32-1fc4-459a-a531-c58ee67445b3",
   "metadata": {},
   "source": [
    "\n",
    "#### Change Type\n",
    "\n",
    "Sentences in this dataset have a new property called `change_type`, indicating what kind of change was made to convert from the original ground truth sentence to the false premise one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd38876-975b-4250-b044-a4f8cee005f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change_Type:  main_subject\n",
      "ref has keys:  dict_keys(['image_id', 'split', 'sentences', 'file_name', 'category_id', 'ann_id', 'sent_ids', 'ref_id'])\n",
      "ref has 4 sentences\n",
      "sent_id:29, is_FP:False, sent: 'a truck number 14 on a snow bank'\n",
      "sent_id:30, is_FP:False, sent: 'a truck with the number 14 painted on it'\n",
      "sent_id:-1, is_FP:True, sent: 'a spaceship number 14 on a snow bank'\n",
      "\tchange_type:  NOT_MAIN_SUBJ\n",
      "\tparent_sent_id: 29, parent_sent: 'a truck number 14 on a snow bank'\n",
      "sent_id:-1, is_FP:True, sent: 'a spaceship with the number 14 painted on it'\n",
      "\tchange_type:  main_subject\n",
      "\tparent_sent_id: 30, parent_sent: 'a truck with the number 14 painted on it'\n"
     ]
    }
   ],
   "source": [
    "def show_change_type(coco: COCO, change_type: str):\n",
    "    for ref_id, ref in coco.refs.items():\n",
    "        for s in ref[\"sentences\"]:\n",
    "            if (\n",
    "                \"change_type\" in s\n",
    "                and s[\"change_type\"]\n",
    "                and s[\"change_type\"] == \"main_subject\"\n",
    "            ):\n",
    "                print(\"Change_Type: \", s[\"change_type\"])\n",
    "                display_ref(ref)\n",
    "                return\n",
    "\n",
    "\n",
    "# show_change_type(coco, \"NOT_MAIN_SUBJ\")\n",
    "show_change_type(coco, \"main_subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f3eb1-e22f-4957-9299-ac766e1aebd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313352d-0339-4a36-be48-683caf00f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2bf9aa-fe01-4bcc-9c6e-f3516f79c029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
