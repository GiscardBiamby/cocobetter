{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf757f92-bcaf-4b0c-929b-26bbbee6812f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f11606b-09dc-4d5c-b0a2-7b1559519e63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbiamby/mambaforge/envs/geo_llm_ret/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Set, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as pil_img\n",
    "import seaborn as sns\n",
    "import simdjson as json\n",
    "import skimage.io as io\n",
    "from geo_llm_ret.fpref.ref_datasets import build_refcoco\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# If you are using normal pycocotools you will need to comment out these three lines and replace with just: from pycocotools.coco import COCO\n",
    "from pycocotools.coco import COCO, Ann, Cat, Image, Ref\n",
    "from pycocotools.helpers import CocoClassDistHelper, get_ref_stats\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3aafea4-8b0a-4ff9-a8a0-e887a3133a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcocog_v002/refs(berkeley_exclude_unified).p'\n",
      "Loaded 49822 refs\n",
      "loading annotations into memory...\n",
      "Done (t=3.46s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "IMG_DIR = Path(\"/shared/gbiamby/data/coco/train2014\")\n",
    "REFSEG_DIR = Path(\"/shared/gbiamby/data/refer_seg\")\n",
    "dataset_name = \"fprefcocog_v002\"\n",
    "split_by = \"berkeley_exclude_unified\"\n",
    "refcoco = build_refcoco(REFSEG_DIR, dataset_name, split_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfdbdd5f-126f-4960-9125-72138c52deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos/neg sentence_counts:  95010 91240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category</th>\n",
       "      <th>supercategory</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>pos_sent_count</th>\n",
       "      <th>neg_sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>0</td>\n",
       "      <td>298801</td>\n",
       "      <td>32</td>\n",
       "      <td>tie</td>\n",
       "      <td>accessory</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>1</td>\n",
       "      <td>453172</td>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "      <td>person</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>2</td>\n",
       "      <td>401571</td>\n",
       "      <td>8</td>\n",
       "      <td>truck</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>3</td>\n",
       "      <td>584873</td>\n",
       "      <td>22</td>\n",
       "      <td>elephant</td>\n",
       "      <td>animal</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>4</td>\n",
       "      <td>1154908</td>\n",
       "      <td>86</td>\n",
       "      <td>vase</td>\n",
       "      <td>indoor</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49817</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>49817</td>\n",
       "      <td>135604</td>\n",
       "      <td>3</td>\n",
       "      <td>car</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49818</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>49818</td>\n",
       "      <td>2166645</td>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "      <td>person</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49819</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>49819</td>\n",
       "      <td>56109</td>\n",
       "      <td>19</td>\n",
       "      <td>horse</td>\n",
       "      <td>animal</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49820</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>49820</td>\n",
       "      <td>584687</td>\n",
       "      <td>22</td>\n",
       "      <td>elephant</td>\n",
       "      <td>animal</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49821</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>49821</td>\n",
       "      <td>1735148</td>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "      <td>person</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49822 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         dataset  ref_id   ann_id  \\\n",
       "0      fprefcocog_v002(berkeley_exclude_unified)       0   298801   \n",
       "1      fprefcocog_v002(berkeley_exclude_unified)       1   453172   \n",
       "2      fprefcocog_v002(berkeley_exclude_unified)       2   401571   \n",
       "3      fprefcocog_v002(berkeley_exclude_unified)       3   584873   \n",
       "4      fprefcocog_v002(berkeley_exclude_unified)       4  1154908   \n",
       "...                                          ...     ...      ...   \n",
       "49817  fprefcocog_v002(berkeley_exclude_unified)   49817   135604   \n",
       "49818  fprefcocog_v002(berkeley_exclude_unified)   49818  2166645   \n",
       "49819  fprefcocog_v002(berkeley_exclude_unified)   49819    56109   \n",
       "49820  fprefcocog_v002(berkeley_exclude_unified)   49820   584687   \n",
       "49821  fprefcocog_v002(berkeley_exclude_unified)   49821  1735148   \n",
       "\n",
       "       category_id  category supercategory  sent_count  pos_sent_count  \\\n",
       "0               32       tie     accessory           4               2   \n",
       "1                1    person        person           4               2   \n",
       "2                8     truck       vehicle           4               2   \n",
       "3               22  elephant        animal           4               2   \n",
       "4               86      vase        indoor           4               2   \n",
       "...            ...       ...           ...         ...             ...   \n",
       "49817            3       car       vehicle           2               1   \n",
       "49818            1    person        person           4               2   \n",
       "49819           19     horse        animal           4               2   \n",
       "49820           22  elephant        animal           4               2   \n",
       "49821            1    person        person           3               2   \n",
       "\n",
       "       neg_sent_count  \n",
       "0                   2  \n",
       "1                   2  \n",
       "2                   2  \n",
       "3                   2  \n",
       "4                   2  \n",
       "...               ...  \n",
       "49817               1  \n",
       "49818               2  \n",
       "49819               2  \n",
       "49820               2  \n",
       "49821               1  \n",
       "\n",
       "[49822 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>pos_sent_count</th>\n",
       "      <th>num_refs</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>total_pos_sents</th>\n",
       "      <th>total_neg_sents</th>\n",
       "      <th>ann_count</th>\n",
       "      <th>img_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>1</td>\n",
       "      <td>4714</td>\n",
       "      <td>9185</td>\n",
       "      <td>4714</td>\n",
       "      <td>4471</td>\n",
       "      <td>208960</td>\n",
       "      <td>25799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>2</td>\n",
       "      <td>45028</td>\n",
       "      <td>176596</td>\n",
       "      <td>90056</td>\n",
       "      <td>86540</td>\n",
       "      <td>208960</td>\n",
       "      <td>25799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fprefcocog_v002(berkeley_exclude_unified)</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>469</td>\n",
       "      <td>240</td>\n",
       "      <td>229</td>\n",
       "      <td>208960</td>\n",
       "      <td>25799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     dataset  pos_sent_count  num_refs  \\\n",
       "0  fprefcocog_v002(berkeley_exclude_unified)               1      4714   \n",
       "1  fprefcocog_v002(berkeley_exclude_unified)               2     45028   \n",
       "2  fprefcocog_v002(berkeley_exclude_unified)               3        80   \n",
       "\n",
       "   sent_count  total_pos_sents  total_neg_sents  ann_count  img_count  \n",
       "0        9185             4714             4471     208960      25799  \n",
       "1      176596            90056            86540     208960      25799  \n",
       "2         469              240              229     208960      25799  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_refs = []\n",
    "df_aggs = []\n",
    "\n",
    "df_refcoco, df_refcoco_agg = get_ref_stats(refcoco, L=1)\n",
    "df_refcoco_agg[\"dataset\"] = f\"{dataset_name}({split_by})\"\n",
    "df_refcoco_agg[\"ann_count\"] = len(refcoco.anns)\n",
    "df_refcoco_agg[\"img_count\"] = len(refcoco.imgs)\n",
    "\n",
    "# Make 'dataset' the first column:\n",
    "df_refcoco_agg.insert(0, \"dataset\", df_refcoco_agg.pop(\"dataset\"))\n",
    "df_aggs.append(df_refcoco_agg)\n",
    "\n",
    "# df_refs\n",
    "df_refcoco[\"dataset\"] = f\"{dataset_name}({split_by})\"\n",
    "df_refcoco.insert(0, \"dataset\", df_refcoco.pop(\"dataset\"))\n",
    "df_refs.append(df_refcoco)\n",
    "\n",
    "df_refs = pd.concat(df_refs)\n",
    "df_aggs = pd.concat(df_aggs)\n",
    "\n",
    "display(df_refs)\n",
    "display(df_aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ad741-78c6-46f7-95ef-8046bc321a3c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a34fa-67ae-4e25-bd4a-815e0f388e57",
   "metadata": {},
   "source": [
    "# Load LISA Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d273d507-c9e0-4d4d-b2cd-b07a96b04560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading clair results for  fprefcoco_v002\n",
      "Loaded 1500 items (images) from preds file: /home/patrickwu/new_lisa/neg_refer_llm/LISA_result/fprefcoco_val/fprefcoco|berkeley_exclude_unified|val.json\n",
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcoco_v002/refs(berkeley_exclude_unified).p'\n",
      "Loaded 50000 refs\n",
      "loading annotations into memory...\n",
      "Done (t=1.07s)\n",
      "creating index...\n",
      "index created!\n",
      "loading clair results for  fprefcoco+_v002\n",
      "Loaded 1500 items (images) from preds file: /home/patrickwu/new_lisa/neg_refer_llm/LISA_result/fprefcoco+_val/fprefcoco+|berkeley_exclude_unified|val.json\n",
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcoco+_v002/refs(berkeley_exclude_unified).p'\n",
      "Loaded 49856 refs\n",
      "loading annotations into memory...\n",
      "Done (t=1.07s)\n",
      "creating index...\n",
      "index created!\n",
      "loading clair results for  fprefcocog_v002\n",
      "Loaded 1300 items (images) from preds file: /home/patrickwu/new_lisa/neg_refer_llm/LISA_result/fprefcocog_val/fprefcocog|berkeley_exclude_unified|val.json\n",
      "Loading refs from '/shared/gbiamby/data/refer_seg/fprefcocog_v002/refs(berkeley_exclude_unified).p'\n",
      "Loaded 49822 refs\n",
      "loading annotations into memory...\n",
      "Done (t=1.12s)\n",
      "creating index...\n",
      "index created!\n",
      "num preds loaded:  51610\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>conversation</th>\n",
       "      <th>pred_sent</th>\n",
       "      <th>gt_exist</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>ref_split</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>559760</td>\n",
       "      <td>/home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000559760.jpg</td>\n",
       "      <td>Please segment guy on right in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.</td>\n",
       "      <td>Sure, [SEG] .</td>\n",
       "      <td>True</td>\n",
       "      <td>2038</td>\n",
       "      <td>val</td>\n",
       "      <td>480245</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tokens': ['guy', 'on', 'right'], 'raw': 'guy on right', 'sent_id': 5819, 'sent': 'guy on right', 'spcy_WORD': ['guy', 'on', 'right'], 'spcy_DEP': ['ROOT', 'prep', 'pobj'], 'spcy_POS': ['NOUN', 'ADP', 'INTJ'], 'spcy_LEM': ['guy', 'on', 'right'], 'spcy_TAG': ['NN', 'IN', 'UH'], 'spcy_IS_STOP': [False, True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['guy'], 'is_false_premise': False, 'exist': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>559760</td>\n",
       "      <td>/home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000559760.jpg</td>\n",
       "      <td>Please segment short guy in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.</td>\n",
       "      <td>Sure, it is [SEG] .</td>\n",
       "      <td>True</td>\n",
       "      <td>2038</td>\n",
       "      <td>val</td>\n",
       "      <td>480245</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tokens': ['short', 'guy'], 'raw': 'short guy', 'sent_id': 5820, 'sent': 'short guy', 'spcy_WORD': ['short', 'guy'], 'spcy_DEP': ['amod', 'ROOT'], 'spcy_POS': ['ADJ', 'NOUN'], 'spcy_LEM': ['short', 'guy'], 'spcy_TAG': ['JJ', 'NN'], 'spcy_IS_STOP': [False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['short guy'], 'is_false_premise': False, 'exist': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>559760</td>\n",
       "      <td>/home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000559760.jpg</td>\n",
       "      <td>Please segment right short guy in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.</td>\n",
       "      <td>Sure, it is [SEG] .</td>\n",
       "      <td>True</td>\n",
       "      <td>2038</td>\n",
       "      <td>val</td>\n",
       "      <td>480245</td>\n",
       "      <td>2</td>\n",
       "      <td>{'tokens': ['right', 'short', 'guy'], 'raw': 'right short guy', 'sent_id': 5821, 'sent': 'right short guy', 'spcy_WORD': ['right', 'short', 'guy'], 'spcy_DEP': ['intj', 'compound', 'ROOT'], 'spcy_POS': ['INTJ', 'PROPN', 'NOUN'], 'spcy_LEM': ['right', 'short', 'guy'], 'spcy_TAG': ['UH', 'NNP', 'NN'], 'spcy_IS_STOP': [False, False, False], 'spcy_ENTS': ['short guy'], 'spcy_NOUN_CHUNKS': ['right short guy'], 'is_false_premise': False, 'exist': True}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ds  image_id  \\\n",
       "0  fprefcoco_v002    559760   \n",
       "1  fprefcoco_v002    559760   \n",
       "2  fprefcoco_v002    559760   \n",
       "\n",
       "                                                                                                  image_path  \\\n",
       "0  /home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000559760.jpg   \n",
       "1  /home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000559760.jpg   \n",
       "2  /home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000559760.jpg   \n",
       "\n",
       "                                                                                                                                  conversation  \\\n",
       "0     Please segment guy on right in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.   \n",
       "1        Please segment short guy in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.   \n",
       "2  Please segment right short guy in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.   \n",
       "\n",
       "             pred_sent  gt_exist  ref_id ref_split  ann_id  sent_idx  \\\n",
       "0        Sure, [SEG] .      True    2038       val  480245         0   \n",
       "1  Sure, it is [SEG] .      True    2038       val  480245         1   \n",
       "2  Sure, it is [SEG] .      True    2038       val  480245         2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                 sent  \n",
       "0                                                {'tokens': ['guy', 'on', 'right'], 'raw': 'guy on right', 'sent_id': 5819, 'sent': 'guy on right', 'spcy_WORD': ['guy', 'on', 'right'], 'spcy_DEP': ['ROOT', 'prep', 'pobj'], 'spcy_POS': ['NOUN', 'ADP', 'INTJ'], 'spcy_LEM': ['guy', 'on', 'right'], 'spcy_TAG': ['NN', 'IN', 'UH'], 'spcy_IS_STOP': [False, True, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['guy'], 'is_false_premise': False, 'exist': True}  \n",
       "1                                                                                              {'tokens': ['short', 'guy'], 'raw': 'short guy', 'sent_id': 5820, 'sent': 'short guy', 'spcy_WORD': ['short', 'guy'], 'spcy_DEP': ['amod', 'ROOT'], 'spcy_POS': ['ADJ', 'NOUN'], 'spcy_LEM': ['short', 'guy'], 'spcy_TAG': ['JJ', 'NN'], 'spcy_IS_STOP': [False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['short guy'], 'is_false_premise': False, 'exist': True}  \n",
       "2  {'tokens': ['right', 'short', 'guy'], 'raw': 'right short guy', 'sent_id': 5821, 'sent': 'right short guy', 'spcy_WORD': ['right', 'short', 'guy'], 'spcy_DEP': ['intj', 'compound', 'ROOT'], 'spcy_POS': ['INTJ', 'PROPN', 'NOUN'], 'spcy_LEM': ['right', 'short', 'guy'], 'spcy_TAG': ['UH', 'NNP', 'NN'], 'spcy_IS_STOP': [False, False, False], 'spcy_ENTS': ['short guy'], 'spcy_NOUN_CHUNKS': ['right short guy'], 'is_false_premise': False, 'exist': True}  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_fpref_preds(preds_path: Path) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load inference results from disk, i.e., load outputs of `lisa_validation_new.py` (or similar\n",
    "    script).\n",
    "    \"\"\"\n",
    "    with open(preds_path, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "        print(f\"Loaded {len(data)} items (images) from preds file: {preds_path}\")\n",
    "        return data\n",
    "\n",
    "\n",
    "def get_sentence_lookup(refcoco: COCO):\n",
    "    \"\"\"Helper method that returns dict whose keys are a tuple of (image_id, ref_id, sent_idx),\n",
    "    values are sent dicts\"\"\"\n",
    "    sent_lookup = {}\n",
    "    for image_id, refs in refcoco.img_to_refs.items():\n",
    "        for ref in refs:\n",
    "            for sent_idx, sent in enumerate(ref[\"sentences\"]):\n",
    "                sent_lookup[(image_id, ref[\"ref_id\"], sent_idx)] = sent\n",
    "    return sent_lookup\n",
    "\n",
    "\n",
    "def is_false_premise(sample: dict) -> bool:\n",
    "    if \"gt_exist\" in sample:\n",
    "        is_fp = not sample[\"gt_exist\"]\n",
    "    elif \"exists\" in sample:\n",
    "        is_fp = not sample[\"exists\"]\n",
    "    elif \"is_false_premise\" in sample:\n",
    "        is_fp = sample[\"is_false_premise\"]\n",
    "    else:\n",
    "        is_fp = False\n",
    "    return is_fp\n",
    "\n",
    "\n",
    "def match_with_refcoco(\n",
    "    preds: dict[str, dict[str, Any]], refseg_dir, dataset_name: str, split_by: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines inference outputs (predictions) with data from the corresponding refcoco dataset. For\n",
    "    example the refcoco dataset has information about which type of modification has been done to\n",
    "    make a sentence a False Premise, or which ground truth sentence each FP sentence maps to, and\n",
    "    what all the ground truth referring expression sentences for the image are.\n",
    "\n",
    "    Input: `preds` is the prediction outputs of `lisa_validation_new.py` (or similar script). Those\n",
    "    results are a dictionary whose keys are image_id (int), and values are a set of predictions for\n",
    "    all the sentences mapped to that image.\n",
    "\n",
    "    Output is a flattened list of results where each element corresponds to a sentence. The image\n",
    "    info is repeated for each sentence. Therefore the output will be longer than the input.\n",
    "    \"\"\"\n",
    "    assert refseg_dir.exists(), str(refseg_dir)\n",
    "    refcoco = build_refcoco(refseg_dir, dataset_name, split_by)\n",
    "    sent_lookup = get_sentence_lookup(refcoco)\n",
    "    path_to_img: dict[str, Image] = {\n",
    "        Path(img[\"file_name\"]).name: img for img_id, img in refcoco.imgs.items()\n",
    "    }\n",
    "    preds_merged = []\n",
    "    for image_path, img_preds in preds.items():\n",
    "        assert len(img_preds[\"pred_sent\"]) == len(\n",
    "            img_preds[\"conversation_list\"]\n",
    "        ), \"lengths don't match: pred_sent and conversation_list\"\n",
    "        assert len(img_preds[\"pred_sent\"]) == len(\n",
    "            img_preds[\"gt_exists\"]\n",
    "        ), \"lengths don't match: pred_sent and gt_exists\"\n",
    "        assert len(img_preds[\"pred_sent\"]) == len(\n",
    "            img_preds[\"ref_ids\"][0]\n",
    "        ), \"lengths don't match: pred_sent and ref_ids     \"\n",
    "        assert len(img_preds[\"pred_sent\"]) == len(\n",
    "            img_preds[\"sent_idxs\"][0]\n",
    "        ), \"lengths don't match: pred_sent and sent_idxs\"\n",
    "        assert len(img_preds[\"pred_sent\"]) == len(\n",
    "            img_preds[\"pred_exists\"]\n",
    "        ), \"lengths don't match: pred_sent and pred_exists\"\n",
    "\n",
    "        image: Image = path_to_img[Path(image_path).name]\n",
    "        img_gt_sents = []\n",
    "        sent_to_ref = {}\n",
    "        for ref in refcoco.img_to_refs[image[\"id\"]]:\n",
    "            for sent_idx, sent in enumerate(ref[\"sentences\"]):\n",
    "                sent_to_ref[(ref[\"ref_id\"], sent_idx)] = ref\n",
    "                if not is_false_premise(sent):\n",
    "                    img_gt_sents.append(sent)\n",
    "\n",
    "        for conversation, pred_sent, gt_exist, ref_id, sent_idx, pred_exist in zip(\n",
    "            img_preds[\"conversation_list\"],\n",
    "            img_preds[\"pred_sent\"],\n",
    "            img_preds[\"gt_exists\"],\n",
    "            img_preds[\"ref_ids\"][0],\n",
    "            img_preds[\"sent_idxs\"][0],\n",
    "            img_preds[\"pred_exists\"],\n",
    "        ):\n",
    "            sent = sent_lookup[(image[\"id\"], ref_id, sent_idx)]\n",
    "            ref = sent_to_ref[(ref_id, sent_idx)]\n",
    "\n",
    "            # Gather gt sents for the current ref:\n",
    "            ref_gt_sents = []\n",
    "            for _ref in refcoco.img_to_refs[image[\"id\"]]:\n",
    "                for _sent in _ref[\"sentences\"]:\n",
    "                    if _ref[\"ref_id\"] == ref_id:\n",
    "                        if not is_false_premise(_sent):\n",
    "                            ref_gt_sents.append(_sent)\n",
    "\n",
    "            merged_pred = {\n",
    "                \"image_id\": image[\"id\"],\n",
    "                \"image_path\": image_path,\n",
    "                \"conversation\": conversation,\n",
    "                \"pred_sent\": pred_sent,\n",
    "                \"gt_exist\": gt_exist,\n",
    "                \"ref_id\": ref[\"ref_id\"],\n",
    "                \"ref_split\": ref[\"split\"],\n",
    "                \"ann_id\": ref[\"ann_id\"],\n",
    "                \"sent_idx\": sent_idx,\n",
    "                # \"pred_exist\": pred_exist,\n",
    "                \"sent\": sent,\n",
    "                # \"img_gt_sents\": img_gt_sents,\n",
    "                # \"ref_gt_sents\": ref_gt_sents,\n",
    "            }\n",
    "            preds_merged.append(merged_pred)\n",
    "    return preds_merged\n",
    "\n",
    "\n",
    "results_paths = [\n",
    "    # LISA\n",
    "    \"/home/patrickwu/new_lisa/neg_refer_llm/LISA_result/fprefcoco_val/fprefcoco|berkeley_exclude_unified|val.json\",\n",
    "    \"/home/patrickwu/new_lisa/neg_refer_llm/LISA_result/fprefcoco+_val/fprefcoco+|berkeley_exclude_unified|val.json\",\n",
    "    \"/home/patrickwu/new_lisa/neg_refer_llm/LISA_result/fprefcocog_val/fprefcocog|berkeley_exclude_unified|val.json\",\n",
    "    # # Hollistic (ours):\n",
    "    # \"/home/gbiamby/proj/geo-llm-ret/lib/clair/output/clair_scores_001/fprefcoco|berkeley_exclude_unified|val-clair_scores-model_gpt-4-turbo.json\",\n",
    "    # \"/home/gbiamby/proj/geo-llm-ret/lib/clair/output/clair_scores_001/fprefcoco+|berkeley_exclude_unified|val-clair_scores-model_gpt-4-turbo.json\",\n",
    "    # \"/home/gbiamby/proj/geo-llm-ret/lib/clair/output/clair_scores_001/fprefcocog|berkeley_exclude_unified|val-clair_scores-model_gpt-4-turbo.json\",\n",
    "    # LLAVA + LISA (ours):\n",
    "    # \"/home/gbiamby/proj/geo-llm-ret/lib/clair/output/clair_scores_cascading_002/fprefcoco|berkeley_exclude_unified|val-clair_scores-model_gpt-4-turbo.json\",\n",
    "    # \"/home/gbiamby/proj/geo-llm-ret/lib/clair/output/clair_scores_cascading_002/fprefcoco+|berkeley_exclude_unified|val-clair_scores-model_gpt-4-turbo.json\",\n",
    "    # \"/home/gbiamby/proj/geo-llm-ret/lib/clair/output/clair_scores_cascading_002/fprefcocog|berkeley_exclude_unified|val-clair_scores-model_gpt-4-turbo.json\",\n",
    "]\n",
    "dfs = []\n",
    "preds_raw = {}\n",
    "for p in results_paths:\n",
    "    ds_name, split_by = Path(p).stem.split(\"|\")[0], Path(p).stem.split(\"|\")[1]\n",
    "    if not ds_name.endswith(\"v002\"):\n",
    "        ds_name += \"_v002\"\n",
    "    print(\"loading clair results for \", ds_name)\n",
    "    preds_raw[ds_name] = load_fpref_preds(p)\n",
    "    preds_flat = match_with_refcoco(preds_raw[ds_name], REFSEG_DIR, ds_name, split_by)\n",
    "    df = pd.DataFrame(preds_flat)\n",
    "    df.insert(0, \"ds\", ds_name)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# Done, show preview:\n",
    "print(\"num preds loaded: \", len(df))\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "30e65cdf-0d9d-42e4-9a5c-f5003f391ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>conversation</th>\n",
       "      <th>pred_sent</th>\n",
       "      <th>gt_exist</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>ref_split</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>sent</th>\n",
       "      <th>has_seg_token</th>\n",
       "      <th>pred_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>716</td>\n",
       "      <td>/home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000000716.jpg</td>\n",
       "      <td>Please segment pesron near large light blue wall in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.</td>\n",
       "      <td>Sure, it is [SEG] .</td>\n",
       "      <td>True</td>\n",
       "      <td>49800</td>\n",
       "      <td>val</td>\n",
       "      <td>1262399</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tokens': ['pesron', 'near', 'large', 'light', 'blue', 'wall'], 'raw': 'Pesron near large light blue wall', 'sent_id': 141409, 'sent': 'pesron near large light blue wall', 'spcy_WORD': ['pesron', 'near', 'large', 'light', 'blue', 'wall'], 'spcy_DEP': ['ROOT', 'prep', 'amod', 'amod', 'amod', 'pobj'], 'spcy_POS': ['NOUN', 'ADP', 'ADJ', 'ADJ', 'ADJ', 'NOUN'], 'spcy_LEM': ['pesron', 'near', 'large', 'light', 'blue', 'wall'], 'spcy_TAG': ['NN', 'IN', 'JJ', 'JJ', 'JJ', 'NN'], 'spcy_IS_STOP': [False, False, False, False, False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['pesron', 'large light blue wall'], 'is_false_premise': False, 'exist': True}</td>\n",
       "      <td>True</td>\n",
       "      <td>(fprefcoco+_v002, 716, 49800, 0, True)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>716</td>\n",
       "      <td>/home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000000716.jpg</td>\n",
       "      <td>Please segment person standing in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.</td>\n",
       "      <td>Sure, it is [SEG] .</td>\n",
       "      <td>True</td>\n",
       "      <td>49800</td>\n",
       "      <td>val</td>\n",
       "      <td>1262399</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tokens': ['person', 'standing'], 'raw': 'person standing', 'sent_id': 141410, 'sent': 'person standing', 'spcy_WORD': ['person', 'standing'], 'spcy_DEP': ['compound', 'ROOT'], 'spcy_POS': ['NOUN', 'NOUN'], 'spcy_LEM': ['person', 'standing'], 'spcy_TAG': ['NN', 'NN'], 'spcy_IS_STOP': [False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['person standing'], 'is_false_premise': False, 'exist': True}</td>\n",
       "      <td>True</td>\n",
       "      <td>(fprefcoco+_v002, 716, 49800, 1, True)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds  image_id  \\\n",
       "8755  fprefcoco+_v002       716   \n",
       "8756  fprefcoco+_v002       716   \n",
       "\n",
       "                                                                                                     image_path  \\\n",
       "8755  /home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000000716.jpg   \n",
       "8756  /home/patrickwu/LISA/dataset_new/refer_seg/images/mscoco/images/train2014/COCO_train2014_000000000716.jpg   \n",
       "\n",
       "                                                                                                                                                       conversation  \\\n",
       "8755  Please segment pesron near large light blue wall in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.   \n",
       "8756                    Please segment person standing in this image if it exists. Otherwise, tell me the object doesn't exist and optionally offer an alternative.   \n",
       "\n",
       "                pred_sent  gt_exist  ref_id ref_split   ann_id  sent_idx  \\\n",
       "8755  Sure, it is [SEG] .      True   49800       val  1262399         0   \n",
       "8756  Sure, it is [SEG] .      True   49800       val  1262399         1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             sent  \\\n",
       "8755  {'tokens': ['pesron', 'near', 'large', 'light', 'blue', 'wall'], 'raw': 'Pesron near large light blue wall', 'sent_id': 141409, 'sent': 'pesron near large light blue wall', 'spcy_WORD': ['pesron', 'near', 'large', 'light', 'blue', 'wall'], 'spcy_DEP': ['ROOT', 'prep', 'amod', 'amod', 'amod', 'pobj'], 'spcy_POS': ['NOUN', 'ADP', 'ADJ', 'ADJ', 'ADJ', 'NOUN'], 'spcy_LEM': ['pesron', 'near', 'large', 'light', 'blue', 'wall'], 'spcy_TAG': ['NN', 'IN', 'JJ', 'JJ', 'JJ', 'NN'], 'spcy_IS_STOP': [False, False, False, False, False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['pesron', 'large light blue wall'], 'is_false_premise': False, 'exist': True}   \n",
       "8756                                                                                                                                                                                                                                                            {'tokens': ['person', 'standing'], 'raw': 'person standing', 'sent_id': 141410, 'sent': 'person standing', 'spcy_WORD': ['person', 'standing'], 'spcy_DEP': ['compound', 'ROOT'], 'spcy_POS': ['NOUN', 'NOUN'], 'spcy_LEM': ['person', 'standing'], 'spcy_TAG': ['NN', 'NN'], 'spcy_IS_STOP': [False, False], 'spcy_ENTS': [], 'spcy_NOUN_CHUNKS': ['person standing'], 'is_false_premise': False, 'exist': True}   \n",
       "\n",
       "      has_seg_token                                 pred_id  \n",
       "8755           True  (fprefcoco+_v002, 716, 49800, 0, True)  \n",
       "8756           True  (fprefcoco+_v002, 716, 49800, 1, True)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"has_seg_token\"] = df.pred_sent.apply(lambda row: \"[SEG]\" in row.upper())\n",
    "df[\"pred_id\"] = df.apply(\n",
    "    lambda row: (\n",
    "        row[\"ds\"],\n",
    "        row[\"image_id\"],\n",
    "        row[\"ref_id\"],\n",
    "        row[\"sent_idx\"],\n",
    "        row[\"gt_exist\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "display(df.sort_values(\"pred_id\").head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "01fd6039-4e5d-4bd2-91cd-dd5697a1c64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = [f\"{x}_{y}\" for x, y in df.columns.to_flat_index()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "81893b00-e54b-4ecb-91cb-f8bb425bfb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_</th>\n",
       "      <th>image_id_nunique</th>\n",
       "      <th>pred_id_nunique</th>\n",
       "      <th>pred_id_count</th>\n",
       "      <th>gt_exist_sum</th>\n",
       "      <th>has_seg_token_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>1500</td>\n",
       "      <td>20962</td>\n",
       "      <td>20962</td>\n",
       "      <td>10758</td>\n",
       "      <td>20962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>1500</td>\n",
       "      <td>21094</td>\n",
       "      <td>21094</td>\n",
       "      <td>10834</td>\n",
       "      <td>21094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fprefcocog_v002</td>\n",
       "      <td>1300</td>\n",
       "      <td>9554</td>\n",
       "      <td>9554</td>\n",
       "      <td>4896</td>\n",
       "      <td>9554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ds_  image_id_nunique  pred_id_nunique  pred_id_count  \\\n",
       "0  fprefcoco+_v002              1500            20962          20962   \n",
       "1   fprefcoco_v002              1500            21094          21094   \n",
       "2  fprefcocog_v002              1300             9554           9554   \n",
       "\n",
       "   gt_exist_sum  has_seg_token_sum  \n",
       "0         10758              20962  \n",
       "1         10834              21094  \n",
       "2          4896               9554  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summ = flatten(\n",
    "    df.groupby([\"ds\"], as_index=False).agg(\n",
    "        {\n",
    "            \"image_id\": [\"nunique\"],\n",
    "            \"pred_id\": [\"nunique\", \"count\"],\n",
    "            \"gt_exist\": [\"sum\", ],\n",
    "            \"has_seg_token\": [\"sum\", ],\n",
    "        }\n",
    "    )\n",
    ")\n",
    "display(df_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63249e54-ea7f-47a6-87f5-15c1fea5f1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_</th>\n",
       "      <th>has_seg_token_</th>\n",
       "      <th>image_id_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>True</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>True</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fprefcocog_v002</td>\n",
       "      <td>True</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ds_  has_seg_token_  image_id_nunique\n",
       "0  fprefcoco+_v002            True              1500\n",
       "1   fprefcoco_v002            True              1500\n",
       "2  fprefcocog_v002            True              1300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summ = flatten(\n",
    "    df.groupby([\"ds\", \"has_seg_token\"], as_index=False).agg(\n",
    "        {\n",
    "            \"image_id\": [\"nunique\"],\n",
    "        }\n",
    "    )\n",
    ")\n",
    "display(df_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "170d98ce-5457-474c-90e1-e273265c9145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_</th>\n",
       "      <th>image_id_nunique</th>\n",
       "      <th>pred_id_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34410</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34400</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34401</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34402</th>\n",
       "      <td>fprefcoco_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17206</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17207</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17208</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17209</th>\n",
       "      <td>fprefcoco+_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51609</th>\n",
       "      <td>fprefcocog_v002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51610 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds_  image_id_nunique  pred_id_nunique\n",
       "0      fprefcoco+_v002                 1                1\n",
       "34410   fprefcoco_v002                 1                1\n",
       "34400   fprefcoco_v002                 1                1\n",
       "34401   fprefcoco_v002                 1                1\n",
       "34402   fprefcoco_v002                 1                1\n",
       "...                ...               ...              ...\n",
       "17206  fprefcoco+_v002                 1                1\n",
       "17207  fprefcoco+_v002                 1                1\n",
       "17208  fprefcoco+_v002                 1                1\n",
       "17209  fprefcoco+_v002                 1                1\n",
       "51609  fprefcocog_v002                 1                1\n",
       "\n",
       "[51610 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summ = flatten(\n",
    "    df.groupby([\"ds\", \"pred_id\"], as_index=False).agg(\n",
    "        {\"image_id\": [\"nunique\"], \"pred_id\": [\"nunique\"]}\n",
    "    )\n",
    ").sort_values([\"pred_id_nunique\"], ascending=False)\n",
    "display(df_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c558ccc-cdab-4f23-8e82-428c25a93687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405346c-8645-47cc-b09d-d555978fd005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea28dbc-ff11-4190-99fe-2e1f1e4c356c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21911ea1-342a-4ab6-a1df-a117164e3c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_llm_ret",
   "language": "python",
   "name": "geo_llm_ret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
